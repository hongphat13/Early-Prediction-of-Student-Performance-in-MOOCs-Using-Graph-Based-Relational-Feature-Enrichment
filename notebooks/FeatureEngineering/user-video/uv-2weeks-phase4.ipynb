{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":232908208,"sourceType":"kernelVersion"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install polars","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import polars as pl\nfrom datetime import datetime\nimport pandas as pd\nimport numpy as np","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"user_filtered_course_df = pl.read_parquet(\"/kaggle/input/user-video-filtered-course/user_filtered_course.parquet\")\nuser_filtered_course_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"uv_filtered_course_df = pl.read_parquet(\"/kaggle/input/user-video-filtered-course/uv_filtered_course.parquet\")\nuv_filtered_course_df[:2, :]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"course_info_limit = pl.read_parquet(\"/kaggle/input/user-video-filtered-course/course_info_limit.parquet\")\ncourse_info_limit[:2, :]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"uv_filtered_course_df = uv_filtered_course_df.drop('seq')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TẠO CỘT LOCAL_START_TIME\nuv_filtered_course_df = uv_filtered_course_df.with_columns(\n    pl.col(\"segments_list\").list.eval(  # Xử lý list ngoài\n        pl.element().list.eval(         # Xử lý list bên trong\n            pl.element().struct.field(\"local_start_time\").cast(pl.Int64)\n        )\n    ).alias(\"local_start_time\")\n)\n\n# Chuyển sang datetime format\nuv_filtered_course_df = uv_filtered_course_df.with_columns(\n    pl.col(\"local_start_time\").list.eval(\n        pl.element().list.eval(  # Xử lý list con\n            pl.from_epoch(pl.element()).dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n        )\n    )\n)\n\nuv_filtered_course_df[:2, :]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols_to_explode = [col for col in uv_filtered_course_df.columns if col != \"user_id\"]\ndf_exploded = uv_filtered_course_df.explode(cols_to_explode)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_exploded.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_exploded = df_exploded.drop('avg_duration_seg', 'num_seg_repeat', 'num_move_seg', 'watch_time', 'perc_miss', 'user_video_ccids', 'seg_intervals', 'p_seg', 'ent_seg')\ndf_exploded.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# GIỮ CÁC PHẦN TỬ CÓ LOCAL_START_TIME NHỎ TRONG VÒNG 14 NAGFY TỪ NGÀY ĐĂNG KÍ\nfrom datetime import datetime, timedelta\n\ndef filter_phase1_fixed(row):\n    enroll_time = pd.to_datetime(row[\"enroll_time\"])\n    local_start_times = pd.to_datetime(row[\"local_start_time\"])\n    \n    keep_idx = [\n        i for i, t in enumerate(local_start_times)\n        if enroll_time  + timedelta(days=42) < t <= enroll_time + timedelta(days=56)\n    ]\n\n    if not keep_idx:\n        return None  # không giữ lại dòng nào\n\n    # Cột giữ nguyên\n    preserved = {\n        \"user_id\": row[\"user_id\"],\n        \"ccid\": row[\"ccid\"],\n        \"course_of_watched_video\": row[\"course_of_watched_video\"],\n        \"enroll_time\": row[\"enroll_time\"],\n        \"video_length\": row[\"video_length\"]\n    }\n\n    # Cột cần lọc\n    list_columns = [\n        \"local_start_time\", \"duration_seg\", \"segments_list\", \"start_points\",\n        \"end_points\", \"speed\", \"watch_time_seg\"\n    ]\n\n    for col in list_columns:\n        try:\n            preserved[col] = [row[col][i] for i in keep_idx]\n        except Exception as e:\n            print(f\"Lỗi khi xử lý cột {col}: {e}\")\n            preserved[col] = None\n\n    return preserved\n\ndf_phase1_pandas = pd.DataFrame(df_exploded.to_pandas().apply(filter_phase1_fixed, axis=1).dropna().to_list())\ndf_phase1 = pl.from_pandas(df_phase1_pandas)\n\ndf_phase1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_phase1.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# GỘP LẠI THEO USER_ID VÀ course_of_watched_video\n\n# Xác định các cột cần gom list\ncols_to_group = [col for col in df_phase1.columns if col not in [\"user_id\", \"course_of_watched_video\"]]\n\n# Group theo user_id và course_of_watched_video, gom list cho các cột còn lại\ndf_grouped_phase1 = df_phase1.group_by([\"user_id\", \"course_of_watched_video\"]).agg([\n    pl.col(col) for col in cols_to_group\n])\n\ndf_grouped_phase1.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_grouped_phase1.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tạo cột video_watch_count_1 là cột đếm số lượng video đã xem trong phase 1\n# bằng cách đếm số phần tử ccid của cột ccid\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.col(\"ccid\").list.unique().list.len().alias(\"video_watch_count_4\")\n])\n\n\ndf_grouped_phase1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"course_dict = (\n    course_info_limit\n    .select([\n        pl.col(\"clean_course_id\"),\n        pl.col(\"ccids\").list.len().alias(\"video_count\")\n    ])\n    .to_dict(as_series=False)\n)\n\n# Chuyển thành dict: key là course id, value là số lượng video\ncourse_video_count = dict(zip(course_dict[\"clean_course_id\"], course_dict[\"video_count\"]))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Tạo cột unique_course\n# course_of_watched_video là 1 giá trị duy nhất (str), nên không cần set hay list\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.col(\"course_of_watched_video\").alias(\"unique_course\")\n])\n\n#  Tính tổng số video theo unique_course dùng course_video_count\n# Hàm xử lý khi unique_course là 1 str duy nhất\ndef total_video_count(course: str) -> int:\n    return course_video_count.get(course, 0)\n\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.col(\"unique_course\").map_elements(total_video_count, return_dtype=pl.Int64).alias(\"total_videos_for_user\")\n])\n\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    (pl.col(\"video_watch_count_4\") * 100 / pl.col(\"total_videos_for_user\")).alias(\"video_watched_percentage_4\")\n])\n\n\ndf_grouped_phase1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cột video_watch_time_1 tổng các thời gian của duration_seg\n\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n\n    # Tính max cho mỗi sublist trong duration_seg\n    pl.col(\"duration_seg\").map_elements(\n        lambda nested: [max(d) if len(d) > 0 else 0 for d in nested],\n        return_dtype=pl.List(pl.Float64)\n    ).alias(\"max_watch_per_video\")\n])\n\n# Tính phần trăm xem trên từng video: max_duration / video_length\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.struct([\"max_watch_per_video\", \"video_length\"]).map_elements(\n        lambda row: [\n            (watched / length) * 100 if length > 0 else 0\n            for watched, length in zip(row[\"max_watch_per_video\"], row[\"video_length\"])\n        ],\n        return_dtype=pl.List(pl.Float64)\n    ).alias(\"watch_percentages\")\n])\n\n# Lấy trung bình các phần trăm để tính video_percentage_watch_time và giới hạn ở 100\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.col(\"watch_percentages\")\n      .list.mean()\n      .clip(upper_bound=100)\n      .alias(\"video_percentage_watch_time_4\")\n])\n\ndf_grouped_phase1 = df_grouped_phase1.drop(['max_watch_per_video', 'watch_percentages'])\n\ndf_grouped_phase1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# tính số lần ngắt quãng (pause) mà user đã có trong phase 1\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.col(\"start_points\")\n      .map_elements(lambda list_of_lists: sum(len(sublist) for sublist in list_of_lists), return_dtype=pl.Int64)\n      .alias(\"video_pause_count_4\")\n])\n\n# tính trung bình số lần ngắt quãng đợt 1 là cột video_pause_avg_1, \n# tính độ lệch chuẩn số lần ngắt quãng đợt 1 là cột video_pause_std_1,\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    # Trung bình số lần ngắt quãng mỗi video\n    pl.col(\"start_points\")\n      .map_elements(lambda list_of_lists: (\n          sum(len(sublist) for sublist in list_of_lists) / len(list_of_lists)\n          if len(list_of_lists) > 0 else 0\n      ), return_dtype=pl.Float64)\n      .alias(\"video_pause_avg_4\"),\n\n    # Độ lệch chuẩn số lần ngắt quãng mỗi video, thay null bằng 0.0\n    pl.col(\"start_points\")\n      .map_elements(lambda list_of_lists: (\n          float(pl.Series([len(sublist) for sublist in list_of_lists]).std())\n          if len(list_of_lists) > 1 else 0.0  # ít nhất phải có 2 video mới tính std được\n      ), return_dtype=pl.Float64)\n      .alias(\"video_pause_std_4\"),\n])\n\ndf_grouped_phase1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TÍNH TRUNG BÌNH, STD SỐ LẦN XEM LẠI\ndef rewatch_counts(start_lists, end_lists):\n    counts = []\n    for starts, ends in zip(start_lists, end_lists):\n        count = 0\n        for i in range(1, len(starts)):\n            if starts[i] < ends[i - 1]:\n                count += 1\n        counts.append(count)\n    return counts\n\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.struct([\"start_points\", \"end_points\"])\n      .map_elements(lambda x: rewatch_counts(x[\"start_points\"], x[\"end_points\"]))\n      .alias(\"video_rewatch_count_4\")\n])\n\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.col(\"video_rewatch_count_4\")\n      .list.eval(pl.element().mean())\n      .list.first()\n      .alias(\"video_rewatch_avg_4\"),\n\n    pl.col(\"video_rewatch_count_4\")\n      .list.eval(pl.element().std(ddof=1))\n      .list.first()\n      .fill_null(0.0)\n      .alias(\"video_rewatch_std_4\"),\n])\n\n\ndf_grouped_phase1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_grouped_phase1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TÍNH THỜI GIAN NGẮT QUÃNG GIỮA CÁC LẦN XEM, TRUNG BÌNH VÀ STD\n#\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.struct([\"start_points\", \"end_points\"]).map_elements(\n        lambda row: [\n            [s_next - e_curr for s_next, e_curr in zip(s[1:], e[:-1])] if len(s) > 1 else [0.0]\n            for s, e in zip(row[\"start_points\"], row[\"end_points\"])\n        ]\n    ).alias(\"video_time_between_views_4\")\n])\n\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    # Tính trung bình\n    pl.col(\"video_time_between_views_4\").map_elements(\n        lambda outer: float(sum([sum(inner) for inner in outer], 0.0)) / max(sum([len(inner) for inner in outer]), 1)\n    ).alias(\"video_time_between_views_avg_4\"),\n\n    # Tính độ lệch chuẩn\n    pl.col(\"video_time_between_views_4\").map_elements(\n        lambda outer: (\n            (lambda flat: float(np.std(flat, ddof=1)) if len(flat) > 1 else 0.0)(\n                [x for inner in outer for x in inner]\n            )\n        )\n    ).alias(\"video_time_between_views_std_4\")\n])\n\ndf_grouped_phase1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TÍNH TRUNG BÌNH TỐC ĐỘ XEM\n\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.col(\"speed\").map_elements(\n        lambda outer: float(\n            sum([sum(inner) / len(inner) if len(inner) > 0 else 0.0 for inner in outer])\n        ) / max(len(outer), 1)\n    ).alias(\"video_speed_avg_4\")\n])\n\ndf_grouped_phase1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# TÍNH ENTROPY CỦA KHOẢNG THỜI GIAN XEM\n\ndef entropy_single(duration_list):\n    total = sum(duration_list)\n    if total == 0 or len(duration_list) == 0:\n        return 0.0\n    probs = [d / total for d in duration_list]\n    return sum([-p * np.log2(p) if p > 0 else 0.0 for p in probs])\n\n# Áp dụng cho từng video trong danh sách duration_seg\ndf_grouped_phase1 = df_grouped_phase1.with_columns([\n    pl.col(\"duration_seg\").map_elements(\n        lambda video_durations: [entropy_single(seg) for seg in video_durations]\n    ).alias(\"ent_seg\")  # đây là entropy của từng video\n])\n\n# Tính trung bình tất cả entropy từ các list trong ent_seg và thêm làm cột entropy_time_1\n# Tính trung bình của các list trong ent_seg\ndf_grouped_phase1 = df_grouped_phase1.with_columns(\n    pl.col(\"ent_seg\").list.mean().alias(\"entropy_time_4\")\n)\n\ndf_grouped_phase1.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_grouped_phase1.write_parquet(\"user_video_phase4.parquet\") \n#course_info_limit_df.write_parquet(\"course_info_limit.parquet\") ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}