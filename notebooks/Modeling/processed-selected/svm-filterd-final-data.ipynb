{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":241303151,"sourceType":"kernelVersion"},{"sourceId":241455282,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport joblib\nimport os\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report\nfrom sklearn.model_selection import RandomizedSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-28T15:54:34.872163Z","iopub.execute_input":"2025-05-28T15:54:34.872366Z","iopub.status.idle":"2025-05-28T15:54:37.680788Z","shell.execute_reply.started":"2025-05-28T15:54:34.872349Z","shell.execute_reply":"2025-05-28T15:54:37.679930Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T15:54:37.682825Z","iopub.execute_input":"2025-05-28T15:54:37.683235Z","iopub.status.idle":"2025-05-28T15:54:37.687072Z","shell.execute_reply.started":"2025-05-28T15:54:37.683215Z","shell.execute_reply":"2025-05-28T15:54:37.686203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"param_dist = {\n    'C': [0.1, 1, 10, 100],\n    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n    'gamma': ['scale', 'auto']\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T15:54:37.690776Z","iopub.execute_input":"2025-05-28T15:54:37.691042Z","iopub.status.idle":"2025-05-28T15:54:37.721234Z","shell.execute_reply.started":"2025-05-28T15:54:37.691020Z","shell.execute_reply":"2025-05-28T15:54:37.720311Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport joblib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import (\n    accuracy_score, f1_score, classification_report, confusion_matrix,\n    roc_auc_score, roc_curve\n)\nfrom sklearn.preprocessing import label_binarize\n\ndef train_phase(phase_path, random_state=42, sample=False):\n    best_model = None\n    best_score = 0\n    all_metrics = []\n    \n    for fold in range(1, 6):\n        fold_path = os.path.join(phase_path, f\"fold{fold}\")\n        scaler = joblib.load(f\"{fold_path}/scaler.pkl\")\n\n        if sample:\n            X_train = pd.read_csv(f\"{fold_path}/X_train_resampled.csv\")\n            y_train = pd.read_csv(f\"{fold_path}/y_train_resampled.csv\").values.ravel()\n            X_train_scaled = X_train\n        else:\n            X_train = pd.read_csv(f\"{fold_path}/X_train.csv\")\n            y_train = pd.read_csv(f\"{fold_path}/y_train.csv\").values.ravel()\n            X_train_scaled = scaler.transform(X_train)\n            X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n\n        X_val = pd.read_csv(f\"{fold_path}/X_val.csv\")\n        y_val = pd.read_csv(f\"{fold_path}/y_val.csv\").values.ravel()\n        X_val_scaled = scaler.transform(X_val)\n        X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_train.columns)\n\n        # SVM model with predefined hyperparameters\n        model = SVC(C=0.1, kernel='rbf', gamma='scale', probability=True, random_state=random_state)\n        model.fit(X_train_scaled, y_train)\n\n        y_pred = model.predict(X_val_scaled)\n        y_proba = model.predict_proba(X_val_scaled)\n\n        acc = accuracy_score(y_val, y_pred)\n        f1 = f1_score(y_val, y_pred, average='macro')\n\n        # AUC\n        classes = model.classes_\n        y_val_bin = label_binarize(y_val, classes=classes)\n        auc = roc_auc_score(y_val_bin, y_proba, average='macro', multi_class='ovr')\n\n        all_metrics.append({'fold': fold, 'accuracy': acc, 'f1_macro': f1, 'auc': auc})\n\n        if f1 > best_score:\n            best_score = f1\n            best_model = model\n            best_scaler = scaler\n            best_fold = fold\n\n        print(f\"\\nFold {fold} Classification Report:\\n\", classification_report(y_val, y_pred))\n\n        # Confusion Matrix\n        cm = confusion_matrix(y_val, y_pred)\n        plt.figure(figsize=(6, 5))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                    xticklabels=classes, yticklabels=classes)\n        plt.title(f'Confusion Matrix - Fold {fold}')\n        plt.xlabel('Predicted')\n        plt.ylabel('True')\n        plt.tight_layout()\n        plt.show()\n\n        # ROC Curve\n        plt.figure(figsize=(8, 6))\n        for i, cls in enumerate(classes):\n            fpr, tpr, _ = roc_curve(y_val_bin[:, i], y_proba[:, i])\n            plt.plot(fpr, tpr, label=f'Class {cls}')\n        plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(f'ROC Curve - Fold {fold}')\n        plt.legend()\n        plt.tight_layout()\n        plt.show()\n\n    # Average metrics\n    avg_metrics = pd.DataFrame(all_metrics).mean().to_dict()\n    print(f\"\\nAverage Accuracy: {avg_metrics['accuracy']:.4f}\")\n    print(f\"Average F1 Macro: {avg_metrics['f1_macro']:.4f}\")\n    print(f\"Average AUC: {avg_metrics['auc']:.4f}\")\n\n    return best_model, best_scaler, best_fold, all_metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T15:54:37.722005Z","iopub.execute_input":"2025-05-28T15:54:37.722288Z","iopub.status.idle":"2025-05-28T15:54:37.738357Z","shell.execute_reply.started":"2025-05-28T15:54:37.722263Z","shell.execute_reply":"2025-05-28T15:54:37.737610Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# import pandas as pd\n# import numpy as np\n# import joblib\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# from sklearn.metrics import (\n#     accuracy_score, f1_score, classification_report, confusion_matrix,\n#     roc_auc_score, roc_curve\n# )\n# from sklearn.preprocessing import LabelEncoder\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.layers import LSTM, Dense, Dropout\n# from tensorflow.keras.utils import to_categorical\n\n\n# def create_ann_lstm_model(n_timesteps, n_features, n_outputs):\n#     model = Sequential()\n#     model._name = 'ANN-LSTM'\n#     model.add(LSTM(200, input_shape=(n_timesteps, n_features), recurrent_dropout=0.2, name=\"LSTM_Layer\"))\n#     model.add(Dropout(0.5, name=\"Dropout_layer\"))\n#     model.add(Dense(100, activation='relu', name=\"ANN_Hidden_Layer\"))\n#     model.add(Dense(n_outputs, activation='softmax', name=\"ANN_Output_Layer\"))\n#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n#     return model\n\n\n# def train_phase(phase_path, random_state=42, sample=False):\n#     best_model = None\n#     best_score = 0\n#     all_metrics = []\n\n#     for fold in range(1, 6):\n#         fold_path = os.path.join(phase_path, f\"fold{fold}\")\n#         scaler = joblib.load(f\"{fold_path}/scaler.pkl\")\n\n#         if sample:\n#             X_train = pd.read_csv(f\"{fold_path}/X_train_resampled.csv\")\n#             y_train = pd.read_csv(f\"{fold_path}/y_train_resampled.csv\").values.ravel()\n#             X_train_scaled = X_train\n#         else:\n#             X_train = pd.read_csv(f\"{fold_path}/X_train.csv\")\n#             y_train = pd.read_csv(f\"{fold_path}/y_train.csv\").values.ravel()\n#             X_train_scaled = scaler.transform(X_train)\n#             X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n\n#         X_val = pd.read_csv(f\"{fold_path}/X_val.csv\")\n#         y_val = pd.read_csv(f\"{fold_path}/y_val.csv\").values.ravel()\n#         X_val_scaled = scaler.transform(X_val)\n#         X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_train.columns)\n\n#         # Encode labels\n#         le = LabelEncoder()\n#         y_train_enc = le.fit_transform(y_train)\n#         y_val_enc = le.transform(y_val)\n\n#         # One-hot encode\n#         y_train_cat = to_categorical(y_train_enc)\n#         y_val_cat = to_categorical(y_val_enc)\n\n#         # Reshape input to (samples, timesteps, features)\n#         X_train_seq = np.expand_dims(X_train_scaled.values, axis=1)\n#         X_val_seq = np.expand_dims(X_val_scaled.values, axis=1)\n\n#         n_timesteps = X_train_seq.shape[1]\n#         n_features = X_train_seq.shape[2]\n#         n_outputs = y_train_cat.shape[1]\n\n#         # Create and train model\n#         model = create_ann_lstm_model(n_timesteps, n_features, n_outputs)\n#         print(f\"\\nFold {fold} - Model Summary:\")\n#         print(model.summary())\n\n#         history = model.fit(\n#             X_train_seq, y_train_cat,\n#             validation_data=(X_val_seq, y_val_cat),\n#             epochs=30, batch_size=32, verbose=0\n#         )\n\n#         # Predict & evaluate\n#         y_proba = model.predict(X_val_seq)\n#         y_pred = np.argmax(y_proba, axis=1)\n#         y_val_true = np.argmax(y_val_cat, axis=1)\n\n#         acc = accuracy_score(y_val_true, y_pred)\n#         f1 = f1_score(y_val_true, y_pred, average='macro')\n#         auc = roc_auc_score(y_val_cat, y_proba, average='macro', multi_class='ovr')\n\n#         all_metrics.append({'fold': fold, 'accuracy': acc, 'f1_macro': f1, 'auc': auc})\n\n#         if f1 > best_score:\n#             best_score = f1\n#             best_model = model\n#             best_scaler = scaler\n#             best_fold = fold\n#             best_encoder = le\n\n#         print(f\"\\nFold {fold} Classification Report:\\n\", classification_report(y_val_true, y_pred, target_names=le.classes_.astype(str)))\n\n#         # Confusion Matrix\n#         cm = confusion_matrix(y_val_true, y_pred)\n#         plt.figure(figsize=(6, 5))\n#         sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n#                     xticklabels=le.classes_, yticklabels=le.classes_)\n#         plt.title(f'Confusion Matrix - Fold {fold}')\n#         plt.xlabel('Predicted')\n#         plt.ylabel('True')\n#         plt.tight_layout()\n#         plt.show()\n\n#         # ROC Curve\n#         plt.figure(figsize=(8, 6))\n#         for i, cls in enumerate(le.classes_):\n#             fpr, tpr, _ = roc_curve(y_val_cat[:, i], y_proba[:, i])\n#             plt.plot(fpr, tpr, label=f'Class {cls}')\n#         plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n#         plt.xlabel('False Positive Rate')\n#         plt.ylabel('True Positive Rate')\n#         plt.title(f'ROC Curve - Fold {fold}')\n#         plt.legend()\n#         plt.tight_layout()\n#         plt.show()\n\n#     # Average metrics\n#     avg_metrics = pd.DataFrame(all_metrics).mean().to_dict()\n#     print(f\"\\nAverage Accuracy: {avg_metrics['accuracy']:.4f}\")\n#     print(f\"Average F1 Macro: {avg_metrics['f1_macro']:.4f}\")\n#     print(f\"Average AUC: {avg_metrics['auc']:.4f}\")\n\n#     return best_model, best_scaler, best_fold, all_metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T16:32:12.336633Z","iopub.execute_input":"2025-05-28T16:32:12.337288Z","iopub.status.idle":"2025-05-28T16:32:12.354294Z","shell.execute_reply.started":"2025-05-28T16:32:12.337264Z","shell.execute_reply":"2025-05-28T16:32:12.353487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"phase_paths = [f\"/kaggle/input/smotesvm-train-filtered-data/outputs/phase{i}\" for i in range(1, 5)]\nresults = {}\n\nfor i, phase_path in enumerate(phase_paths, start=1):\n    print(f\"\\n===================================\")\n    print(f\"\\n======= Training Phase {i} ========\")\n    print(f\"\\n===================================\")\n    sample = False\n    model, scaler, best_fold, metrics = train_phase(phase_path, sample = sample)\n    # Save best model & scaler\n    if sample: \n        temp = \"sample\"\n    else: temp = \"no_sample\"\n    joblib.dump(model, f\"best_model_{temp}_phase{i}.pkl\")\n    joblib.dump(scaler, f\"best_scaler_{temp}_phase{i}.pkl\")\n    results[f\"phase{i}\"] = metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T16:32:55.998812Z","iopub.execute_input":"2025-05-28T16:32:55.999424Z","iopub.status.idle":"2025-05-28T16:40:05.473098Z","shell.execute_reply.started":"2025-05-28T16:32:55.999402Z","shell.execute_reply":"2025-05-28T16:40:05.472457Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Predict on Test Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport joblib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\nfrom sklearn.preprocessing import label_binarize\n\ndef predict_on_test(test_file_path, model_file, scaler_file, school_mapping_file):\n    # Load model, scaler, and mapping\n    model = joblib.load(model_file)\n    scaler = joblib.load(scaler_file)\n    mapping = joblib.load(school_mapping_file)\n\n    # Load and preprocess test data\n    df_test = pd.read_csv(test_file_path)\n    y_test = df_test['label_encoded']\n    X_test = df_test.drop(columns=['user_id', 'course_id', 'label_encoded', 'label', 'total_score'], axis=1)\n\n    # Apply school mapping\n    if 'school' in X_test.columns:\n        X_test['school'] = X_test['school'].map(mapping).fillna(0).astype(int)\n\n    # Scale features\n    X_test_scaled = scaler.transform(X_test)\n\n    # Predict\n    y_pred = model.predict(X_test_scaled)\n    y_proba = model.predict_proba(X_test_scaled)\n\n    # Classification Report\n    print(\"\\nClassification Report:\\n\")\n    print(classification_report(y_test, y_pred))\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)\n    plt.title('Confusion Matrix')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.tight_layout()\n    plt.show()\n\n    # AUC Score\n    classes = model.classes_\n    y_test_bin = label_binarize(y_test, classes=classes)\n    auc_score = roc_auc_score(y_test_bin, y_proba, average='macro', multi_class='ovr')\n    print(f\"\\nTest AUC (macro-average, OVR): {auc_score:.4f}\")\n\n    # Plot ROC Curves\n    plt.figure(figsize=(8, 6))\n    for i, cls in enumerate(classes):\n        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba[:, i])\n        plt.plot(fpr, tpr, label=f'Class {cls}')\n\n    plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n    plt.title('ROC Curves for Test Set')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\n    return y_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T16:41:03.381457Z","iopub.execute_input":"2025-05-28T16:41:03.381716Z","iopub.status.idle":"2025-05-28T16:41:03.390778Z","shell.execute_reply.started":"2025-05-28T16:41:03.381699Z","shell.execute_reply":"2025-05-28T16:41:03.390235Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# import joblib\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n# from sklearn.preprocessing import label_binarize\n\n\n# def predict_on_test(test_file_path, model_file, scaler_file, school_mapping_file):\n#     import numpy as np\n\n#     # Load model, scaler và mapping\n#     model = joblib.load(model_file)  # Đây là Keras model lưu bằng joblib\n#     scaler = joblib.load(scaler_file)\n#     mapping = joblib.load(school_mapping_file)\n\n#     # Load test data\n#     df_test = pd.read_csv(test_file_path)\n#     y_test = df_test['label_encoded'].values\n#     X_test = df_test.drop(columns=['user_id', 'course_id', 'label_encoded', 'label', 'total_score'], axis=1)\n\n#     if 'school' in X_test.columns:\n#         X_test['school'] = X_test['school'].map(mapping).fillna(0).astype(int)\n\n#     # Scale\n#     X_test_scaled = scaler.transform(X_test)\n\n#     # ✅ THÊM DÒNG NÀY: reshape thành (batch, time_steps=1, features)\n#     X_test_scaled = np.expand_dims(X_test_scaled, axis=1)\n\n#     # Predict\n#     y_proba = model.predict(X_test_scaled)\n#     y_pred = np.argmax(y_proba, axis=1)\n\n#     # Classification Report\n#     print(\"\\nClassification Report:\\n\")\n#     print(classification_report(y_test, y_pred))\n\n#     # Confusion Matrix\n#     cm = confusion_matrix(y_test, y_pred)\n#     plt.figure(figsize=(8, 6))\n#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n#     plt.title('Confusion Matrix')\n#     plt.xlabel('Predicted')\n#     plt.ylabel('True')\n#     plt.tight_layout()\n#     plt.show()\n\n#     # AUC\n#     classes = np.unique(y_test)\n#     y_test_bin = label_binarize(y_test, classes=classes)\n#     auc_score = roc_auc_score(y_test_bin, y_proba, average='macro', multi_class='ovr')\n#     print(f\"\\nTest AUC (macro-average, OVR): {auc_score:.4f}\")\n\n#     # ROC Curves\n#     plt.figure(figsize=(8, 6))\n#     for i, cls in enumerate(classes):\n#         fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_proba[:, i])\n#         plt.plot(fpr, tpr, label=f'Class {cls}')\n#     plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n#     plt.title('ROC Curves for Test Set')\n#     plt.xlabel('False Positive Rate')\n#     plt.ylabel('True Positive Rate')\n#     plt.legend()\n#     plt.tight_layout()\n#     plt.show()\n\n#     return y_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T17:51:15.022966Z","iopub.execute_input":"2025-05-28T17:51:15.023225Z","iopub.status.idle":"2025-05-28T17:51:15.032223Z","shell.execute_reply.started":"2025-05-28T17:51:15.023206Z","shell.execute_reply":"2025-05-28T17:51:15.031553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\n\nfor i in range(1, 5):\n    test_dir = f'/kaggle/input/filtered-final-data/phase{i}/user_train_phase_{i}_test.csv'\n    \n    # Get model and scaler using glob\n    model_path = f'/kaggle/working/best_model_{temp}_phase{i}.pkl'\n    scaler_path = f'/kaggle/working/best_scaler_{temp}_phase{i}.pkl'\n    \n    # School mapping path\n    school_mapping_file = f'/kaggle/input/smotesvm-train-filtered-data/outputs/phase{i}/mappings/school_mapping.pkl'\n\n    # Predict on test set\n    predict_on_test(test_dir, model_path, scaler_path, school_mapping_file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T17:51:17.561109Z","iopub.execute_input":"2025-05-28T17:51:17.561384Z","iopub.status.idle":"2025-05-28T17:51:17.571568Z","shell.execute_reply.started":"2025-05-28T17:51:17.561364Z","shell.execute_reply":"2025-05-28T17:51:17.570548Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Add SMOTE Sample","metadata":{}},{"cell_type":"code","source":"phase_paths = [f\"/kaggle/input/smotesvm-train-filtered-data/outputs/phase{i}\" for i in range(1, 5)]\nresults = {}\n\nfor i, phase_path in enumerate(phase_paths, start=1):\n    print(f\"\\n=== Training Phase {i} ===\")\n    sample = True\n    model, scaler, best_fold, metrics = train_phase(phase_path, sample = sample)\n    # Save best model & scaler\n    if sample: \n        temp = \"sample\"\n    else: temp = \"no_sample\"\n    joblib.dump(model, f\"best_model_{temp}_phase{i}.pkl\")\n    joblib.dump(scaler, f\"best_scaler_{temp}_phase{i}.pkl\")\n    results[f\"phase{i}\"] = metrics\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T15:56:23.560153Z","iopub.status.idle":"2025-05-28T15:56:23.560392Z","shell.execute_reply.started":"2025-05-28T15:56:23.560271Z","shell.execute_reply":"2025-05-28T15:56:23.560283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\n\nfor i in range(1, 5):\n    test_dir = f'/kaggle/input/filtered-final-data/phase{i}/user_train_phase_{i}_test.csv'\n    \n    # Get model and scaler using glob\n    model_path = f'/kaggle/working/best_model_{temp}_phase{i}.pkl'\n    scaler_path = f'/kaggle/working/best_scaler_{temp}_phase{i}.pkl'\n    \n    # School mapping path\n    school_mapping_file = f'/kaggle/input/smotesvm-train-filtered-data/outputs/phase{i}/mappings/school_mapping.pkl'\n\n    # Predict on test set\n    predict_on_test(test_dir, model_path, scaler_path, school_mapping_file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T15:56:23.561826Z","iopub.status.idle":"2025-05-28T15:56:23.562034Z","shell.execute_reply.started":"2025-05-28T15:56:23.561933Z","shell.execute_reply":"2025-05-28T15:56:23.561942Z"}},"outputs":[],"execution_count":null}]}